ğŸ–±ï¸ Virtual Mouse Controller using AI & Computer Vision
ğŸ“Œ Overview

The Virtual Mouse Controller is an AI-powered application that allows users to control the mouse cursor using hand gestures captured through a webcam.
This project leverages Computer Vision and Machine Learning techniques to detect hand landmarks and translate gestures into mouse actions such as move, click, and scroll.

This system eliminates the need for physical mouse devices and demonstrates a practical application of AI in Humanâ€“Computer Interaction (HCI).

ğŸš€ Features

ğŸ¥ Real-time hand detection using webcam

âœ‹ Gesture-based mouse movement

ğŸ–±ï¸ Left click & right click using finger gestures

ğŸ”„ Scroll functionality

âš¡ Smooth and responsive cursor control

ğŸ§  AI & Computer Vision based logic

ğŸ› ï¸ Technologies Used

Python

OpenCV

MediaPipe

PyAutoGUI

NumPy

ğŸ“‚ Project Structure
virtual_mouse_controller/
â”‚
â”œâ”€â”€ main.py                 # Main execution file
â”œâ”€â”€ hand_tracking.py        # Hand landmark detection logic
â”œâ”€â”€ requirements.txt        # Required Python libraries
â”œâ”€â”€ README.md               # Project documentation
â””â”€â”€ .gitignore              # Ignored files

âš™ï¸ Installation & Setup
1ï¸âƒ£ Clone the Repository
git clone https://github.com/YOUR_USERNAME/virtual_mouse_controller.git
cd virtual_mouse_controller

2ï¸âƒ£ Create Virtual Environment (Optional but Recommended)
python -m venv venv
venv\Scripts\activate

3ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

â–¶ï¸ How to Run
python main.py


ğŸ“¸ Ensure your webcam is connected before running the program.

ğŸ§  How It Works

Webcam captures real-time video frames

MediaPipe detects hand landmarks

Specific finger gestures are identified

Gestures are mapped to mouse actions using PyAutoGUI

Cursor moves and performs actions accordingly

ğŸ“Š Use Cases

Touchless computer interaction

Assistive technology for physically challenged users

AI-based automation demonstrations

Humanâ€“Computer Interaction projects

ğŸ”® Future Enhancements

Multi-hand support

Gesture customization

GUI for calibration

Improved accuracy using deep learning models
